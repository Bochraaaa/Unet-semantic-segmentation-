{"cells":[{"cell_type":"code","execution_count":null,"id":"c1c327c2","metadata":{"id":"c1c327c2"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","from matplotlib import pyplot as plt\n","import cv2\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.utils import to_categorical ,Sequence\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\n","from tensorflow.keras.optimizers import Adadelta, Nadam ,Adam\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard\n"]},{"cell_type":"code","execution_count":null,"id":"0e47780b","metadata":{"id":"0e47780b","outputId":"03f86dce-250c-4dda-95dc-b993b87a698e"},"outputs":[{"name":"stdout","output_type":"stream","text":["['.ipynb_checkpoints', '16 filt - Copie.ipynb', 'best_weights.h5', 'class_dict.csv', 'logs', 'Nouveau dossier', 'test', 'test_labels', 'top-weights.h5', 'train', 'train_labels', 'val', 'val_labels']\n"]}],"source":["import os\n","print(os.listdir(\"C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/\"))\n","from glob import glob\n","from pathlib import Path\n","import shutil\n","from tqdm import tqdm_notebook\n","from random import sample, choice"]},{"cell_type":"code","execution_count":null,"id":"8b78a60c","metadata":{"id":"8b78a60c","outputId":"8359f201-bcfb-4310-8391-dfa3229f4a36"},"outputs":[{"data":{"text/plain":["[WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/.ipynb_checkpoints'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/16 filt - Copie.ipynb'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/best_weights.h5'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/class_dict.csv'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/logs'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/Nouveau dossier'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/test'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/test_labels'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/top-weights.h5'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/train'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/train_labels'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/val'),\n"," WindowsPath('C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/val_labels')]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset_path = Path(\"C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/\")\n","list(dataset_path.iterdir())"]},{"cell_type":"code","execution_count":null,"id":"afe66801","metadata":{"id":"afe66801"},"outputs":[],"source":["def tree(directory):\n","    print(f'+ {directory}')\n","    for path in sorted(directory.rglob('*')):\n","        depth = len(path.relative_to(directory).parts)\n","        spacer = '    ' * depth\n","        print(f'{spacer}+ {path.name}')   "]},{"cell_type":"code","execution_count":null,"id":"bf233e4c","metadata":{"id":"bf233e4c"},"outputs":[],"source":["train_imgs = list((dataset_path / \"train\").glob(\"*.png\"))\n","train_labels = list((dataset_path / \"train_labels\").glob(\"*.png\"))\n","val_imgs = list((dataset_path / \"val\").glob(\"*.png\"))\n","val_labels = list((dataset_path / \"val_labels\").glob(\"*.png\"))\n","test_imgs = list((dataset_path / \"test\").glob(\"*.png\"))\n","test_labels = list((dataset_path / \"test_labels\").glob(\"*.png\"))\n","\n","(len(train_imgs),len(train_labels)), (len(val_imgs),len(val_labels)) , (len(test_imgs),len(test_labels))\n","\n","img_size = 512"]},{"cell_type":"code","execution_count":null,"id":"e57e11d3","metadata":{"id":"e57e11d3"},"outputs":[],"source":["assert len(train_imgs) == len(train_labels), \"No of Train images and label mismatch\"\n","assert len(val_imgs) == len(val_labels), \"No of Train images and label mismatch\"\n","assert len(test_imgs) == len(test_labels), \"No of Train images and label mismatch\"\n","\n","sorted(train_imgs), sorted(train_labels), sorted(val_imgs), sorted(val_labels), sorted(test_imgs), sorted(test_labels);"]},{"cell_type":"code","execution_count":null,"id":"5502cf86","metadata":{"id":"5502cf86"},"outputs":[],"source":["for im in train_imgs:\n","    assert dataset_path / \"train_labels\" / (im.stem +\"_L.png\") in train_labels , \"{im} noht there in label folder\"\n","for im in val_imgs:\n","    assert dataset_path / \"val_labels\" / (im.stem +\"_L.png\") in val_labels , \"{im} not there in label folder\"\n","for im in test_imgs:\n","    assert dataset_path / \"test_labels\" / (im.stem +\"_L.png\") in test_labels , \"{im} not there in label folder\""]},{"cell_type":"code","execution_count":null,"id":"7f588bd2","metadata":{"id":"7f588bd2"},"outputs":[],"source":["def make_pair(img,label,dataset):\n","    pairs = []\n","    for im in img:\n","        pairs.append((im , dataset / label / (im.stem +\"_L.png\")))\n","    \n","    return pairs"]},{"cell_type":"code","execution_count":null,"id":"e98db50a","metadata":{"id":"e98db50a"},"outputs":[],"source":["train_pair = make_pair(train_imgs, \"train_labels\", dataset_path)\n","val_pair = make_pair(val_imgs, \"val_labels\", dataset_path)\n","test_pair = make_pair(test_imgs, \"test_labels\", dataset_path)"]},{"cell_type":"code","execution_count":null,"id":"e96846e5","metadata":{"id":"e96846e5","outputId":"c5b6b529-00d6-4e37-9da7-3516b182202f"},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x22c8692c730>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["temp = choice(train_pair)\n","img = img_to_array(load_img(temp[0], target_size=(img_size,img_size)))\n","mask = img_to_array(load_img(temp[1], target_size = (img_size,img_size)))\n","plt.figure(figsize=(10,10))\n","plt.subplot(121)\n","plt.imshow(img/255)\n","plt.subplot(122)\n","plt.imshow(mask/255)"]},{"cell_type":"code","execution_count":null,"id":"7f150903","metadata":{"id":"7f150903","outputId":"ed25d863-be7a-4eef-fb08-4cb9a79bd07b"},"outputs":[{"name":"stdout","output_type":"stream","text":["['name', 'r', 'g', 'b']\n"]}],"source":["class_map_df = pd.read_csv(dataset_path / \"class_dict.csv\", sep=r'\\s*,\\s*',\n","                           header=0, encoding='ascii', engine='python')\n","print(class_map_df.columns.tolist())"]},{"cell_type":"code","execution_count":null,"id":"6758a8d8","metadata":{"id":"6758a8d8","outputId":"2cc7e6fb-d79d-4611-8592-472ad35b130f"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["class_map = []\n","for index,item in class_map_df.iterrows():\n","    class_map.append(np.array([item['r'], item['g'], item['b']]))\n","    \n","len(class_map)"]},{"cell_type":"code","execution_count":null,"id":"2e5a3dab","metadata":{"id":"2e5a3dab"},"outputs":[],"source":["def assert_map_range(mask,class_map):\n","    mask = mask.astype(\"uint8\")\n","    \n","    \n","    \n","    for j in range(img_size):\n","        for k in range(img_size):\n","            assert mask[j][k] in class_map , tuple(mask[j][k])"]},{"cell_type":"code","execution_count":null,"id":"fcd9fa2f","metadata":{"id":"fcd9fa2f"},"outputs":[],"source":["def form_2D_label(mask,class_map):\n","    mask = mask.astype(\"uint8\")\n","    label = np.zeros(mask.shape[:2],dtype= np.uint8)\n","    \n","    for i, rgb in enumerate(class_map):\n","        label[(mask == rgb).all(axis=2)] = i\n","    \n","    return label"]},{"cell_type":"code","execution_count":null,"id":"5349f7b0","metadata":{"id":"5349f7b0","outputId":"bf5475cd-a2c2-4e02-9ec7-a94bcb2379b5"},"outputs":[{"data":{"text/plain":["(array([1], dtype=uint8), array([262144], dtype=int64))"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["lab = form_2D_label(mask,class_map)\n","np.unique(lab,return_counts=True)"]},{"cell_type":"code","execution_count":null,"id":"b33be339","metadata":{"id":"b33be339"},"outputs":[],"source":["class DataGenerator(Sequence):\n","    'Generates data for Keras'\n","    \n","    def __init__(self, pair, class_map, batch_size=16, dim=(img_size,img_size,3), shuffle=True):\n","        'Initialization'\n","        self.dim = dim\n","        self.pair = pair\n","        self.class_map = class_map\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.pair) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [k for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.pair))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        batch_imgs = list()\n","        batch_labels = list()\n","\n","        # Generate data\n","        for i in list_IDs_temp:\n","            # Store sample\n","            img = load_img(self.pair[i][0] ,target_size=self.dim)\n","            img = img_to_array(img)/255.\n","            batch_imgs.append(img)\n","\n","            label = load_img(self.pair[i][1],target_size=self.dim)\n","            label = img_to_array(label)\n","            label = form_2D_label(label,self.class_map)\n","            label = to_categorical(label , num_classes = 4)\n","            batch_labels.append(label)\n","            \n","        return np.array(batch_imgs) ,np.array(batch_labels)"]},{"cell_type":"code","execution_count":null,"id":"d3821b1d","metadata":{"id":"d3821b1d","outputId":"06060ab0-64e3-4b91-984d-e2f4253d54bf"},"outputs":[{"data":{"text/plain":["720"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_generator = DataGenerator(train_pair,class_map,batch_size=16, dim=(img_size,img_size,3) ,shuffle=True)\n","train_steps = train_generator.__len__()\n","train_steps"]},{"cell_type":"code","execution_count":null,"id":"bf5dab85","metadata":{"id":"bf5dab85","outputId":"f2909004-ed08-4e6f-eb7b-880634d8f68a"},"outputs":[{"data":{"text/plain":["(16, 512, 512, 4)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["X,y = train_generator.__getitem__(1)\n","y.shape"]},{"cell_type":"code","execution_count":null,"id":"2c026de0","metadata":{"id":"2c026de0","outputId":"03dfdc9a-1de8-4999-9cf3-84ca27222cd2"},"outputs":[{"data":{"text/plain":["90"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["val_generator = DataGenerator(val_pair, class_map, batch_size=16, dim=(img_size,img_size,3) ,shuffle=True)\n","val_steps = val_generator.__len__()\n","val_steps"]},{"cell_type":"code","execution_count":null,"id":"22dc8cb9","metadata":{"id":"22dc8cb9"},"outputs":[],"source":["def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n","    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    return x\n","\n","\n","def deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n","    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n","    y = concatenate([y, residual], axis=3)\n","    y = conv_block(y, nfilters)\n","    return y\n","\n","\n","def Unet(h, w, filters):\n","# down\n","    input_layer = Input(shape=(img_size, img_size, 3), name='image_input')\n","    conv1 = conv_block(input_layer, nfilters=filters)\n","    conv2 = conv_block(conv1, nfilters=filters)\n","    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    ################################\n","    conv3 = conv_block(conv1_out, nfilters=filters*2)\n","    conv4 = conv_block(conv3, nfilters=filters*2)\n","    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n","    ########################################################\n","    conv5 = conv_block(conv2_out, nfilters=filters*4)\n","    conv6 = conv_block(conv5, nfilters=filters*4)\n","    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv6)\n","    #############################################################\n","    conv7 = conv_block(conv3_out, nfilters=filters*8)\n","    conv8 = conv_block(conv7, nfilters=filters*8)\n","    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv8)\n","    conv4_out = Dropout(0.3)(conv4_out)\n","    #######################################################\n","    conv9 = conv_block(conv4_out, nfilters=filters*16)\n","    conv10 = conv_block(conv9, nfilters=filters*16)\n","    conv11 = Dropout(0.3)(conv10)\n","    #changer DO 0.3 0.5 0.75\n","# up\n","    deconv6 = deconv_block(conv11, residual=conv8, nfilters=filters*8)\n","    deconv6 = Dropout(0.3)(deconv6)\n","    deconv7 = deconv_block(deconv6, residual=conv6, nfilters=filters*4)\n","    deconv7 = Dropout(0.3)(deconv7) \n","    deconv8 = deconv_block(deconv7, residual=conv4, nfilters=filters*2)\n","    deconv9 = deconv_block(deconv8, residual=conv2, nfilters=filters)\n","    output_layer = Conv2D(filters=4, kernel_size=(1, 1), activation='softmax')(deconv9)\n","\n","    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"01b48563","metadata":{"id":"01b48563","outputId":"56390dcb-8dfc-4ab3-c79a-ab9df84f2f79"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Unet\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," image_input (InputLayer)       [(None, 512, 512, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 512, 512, 32  896         ['image_input[0][0]']            \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 512, 512, 32  128        ['conv2d[0][0]']                 \n"," alization)                     )                                                                 \n","                                                                                                  \n"," activation (Activation)        (None, 512, 512, 32  0           ['batch_normalization[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 512, 512, 32  9248        ['activation[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 512, 512, 32  128        ['conv2d_1[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_1 (Activation)      (None, 512, 512, 32  0           ['batch_normalization_1[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 512, 512, 32  9248        ['activation_1[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 512, 512, 32  128        ['conv2d_2[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_2 (Activation)      (None, 512, 512, 32  0           ['batch_normalization_2[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 512, 512, 32  9248        ['activation_2[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 512, 512, 32  128        ['conv2d_3[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_3 (Activation)      (None, 512, 512, 32  0           ['batch_normalization_3[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 256, 256, 32  0           ['activation_3[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 256, 256, 64  18496       ['max_pooling2d[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 256, 256, 64  256        ['conv2d_4[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_4 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_4[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 256, 256, 64  36928       ['activation_4[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 256, 256, 64  256        ['conv2d_5[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_5 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_5[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 256, 256, 64  36928       ['activation_5[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 256, 256, 64  256        ['conv2d_6[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_6 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_6[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 256, 256, 64  36928       ['activation_6[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 256, 256, 64  256        ['conv2d_7[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_7 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_7[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64  0          ['activation_7[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d_1[0][0]']        \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 128, 128, 12  512        ['conv2d_8[0][0]']               \n"," rmalization)                   8)                                                                \n","                                                                                                  \n"," activation_8 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_8[0][0]']  \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 128, 128, 12  147584      ['activation_8[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 128, 128, 12  512        ['conv2d_9[0][0]']               \n"," rmalization)                   8)                                                                \n","                                                                                                  \n"," activation_9 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_9[0][0]']  \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 128, 128, 12  147584      ['activation_9[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 128, 128, 12  512        ['conv2d_10[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_10 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_10[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 128, 128, 12  147584      ['activation_10[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 128, 128, 12  512        ['conv2d_11[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_11 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_11[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_11[0][0]']          \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_12[0][0]']          \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_13[0][0]']          \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_14 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_14[0][0]']          \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_15[0][0]']          \n","                                                                                                  \n"," dropout (Dropout)              (None, 32, 32, 256)  0           ['max_pooling2d_3[0][0]']        \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 32, 32, 512)  1180160     ['dropout[0][0]']                \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_16[0][0]']          \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_17[0][0]']          \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_18 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_18[0][0]']          \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 32, 32, 512)  0           ['activation_19[0][0]']          \n","                                                                                                  \n"," conv2d_transpose (Conv2DTransp  (None, 64, 64, 256)  1179904    ['dropout_1[0][0]']              \n"," ose)                                                                                             \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 64, 64, 512)  0           ['conv2d_transpose[0][0]',       \n","                                                                  'activation_15[0][0]']          \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate[0][0]']            \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_20[0][0]']          \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_21 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_21[0][0]'] \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 64, 64, 256)  0           ['activation_21[0][0]']          \n","                                                                                                  \n"," conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 12  295040     ['dropout_2[0][0]']              \n"," spose)                         8)                                                                \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_1[0][0]',     \n","                                6)                                'activation_11[0][0]']          \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_1[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 128, 128, 12  512        ['conv2d_22[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_22 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_22[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 128, 128, 12  147584      ['activation_22[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 128, 128, 12  512        ['conv2d_23[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_23 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_23[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 128, 128, 12  0           ['activation_23[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 64  73792      ['dropout_3[0][0]']              \n"," spose)                         )                                                                 \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_2[0][0]',     \n","                                8)                                'activation_7[0][0]']           \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_2[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 256, 256, 64  256        ['conv2d_24[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_24 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_24[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 256, 256, 64  36928       ['activation_24[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 256, 256, 64  256        ['conv2d_25[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_25 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_25[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 32  18464      ['activation_25[0][0]']          \n"," spose)                         )                                                                 \n","                                                                                                  \n"," concatenate_3 (Concatenate)    (None, 512, 512, 64  0           ['conv2d_transpose_3[0][0]',     \n","                                )                                 'activation_3[0][0]']           \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 512, 512, 32  18464       ['concatenate_3[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 512, 512, 32  128        ['conv2d_26[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_26 (Activation)     (None, 512, 512, 32  0           ['batch_normalization_26[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 512, 512, 32  9248        ['activation_26[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 512, 512, 32  128        ['conv2d_27[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_27 (Activation)     (None, 512, 512, 32  0           ['batch_normalization_27[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 512, 512, 4)  132         ['activation_27[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 14,937,604\n","Trainable params: 14,927,748\n","Non-trainable params: 9,856\n","__________________________________________________________________________________________________\n"]}],"source":["model = Unet(img_size,img_size, 32)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"26069708","metadata":{"id":"26069708"},"outputs":[],"source":["import tensorflow as tf\n","recall = tf.keras.metrics.Recall()\n","precision = tf.keras.metrics.Precision()\n","model.compile(optimizer = Adam(learning_rate = 0.00001\n","), loss = ['categorical_crossentropy'], metrics = ['accuracy',precision, recall])\n"," \n","#model.compile(optimizer='adam',(lr = 0.01), loss='categorical_crossentropy' ,  metrics = ['accuracy',precision, recall])\n"]},{"cell_type":"code","execution_count":null,"id":"db434b0a","metadata":{"id":"db434b0a"},"outputs":[],"source":["mc = ModelCheckpoint(mode='max', filepath='top-weights.h5', monitor='loss',save_best_only='True', save_weights_only='True', verbose=1)\n","es = EarlyStopping(mode='max', monitor='accuracy', patience=10, verbose=0)\n","tb = TensorBoard(log_dir=\"logs/\", histogram_freq=0, write_graph=True, write_images=False)\n","#rl = ReduceLROnPlateau(monitor='accuracy',factor=0.1 ,patience=5,verbose=1,mode=\"max\",min_lr=0.01)\n","cv = CSVLogger(\"logs/log.csv\" , append=True , separator=',')\n","lr = 0.01\n"]},{"cell_type":"code","execution_count":null,"id":"f0377a8b","metadata":{"scrolled":false,"id":"f0377a8b","outputId":"da48c5b2-4059-4ec7-f239-86e1b5cf946c"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\maste\\AppData\\Local\\Temp/ipykernel_7456/1128431050.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  results = model.fit_generator(train_generator , steps_per_epoch=train_steps , epochs=150,\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","720/720 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.9032 - precision: 0.9549 - recall: 0.5752\n","Epoch 00001: loss improved from -inf to 0.76792, saving model to top-weights.h5\n","720/720 [==============================] - 424s 571ms/step - loss: 0.7679 - accuracy: 0.9032 - precision: 0.9549 - recall: 0.5752 - val_loss: 0.5229 - val_accuracy: 0.9860 - val_precision: 0.9919 - val_recall: 0.9477\n","Epoch 2/150\n","720/720 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.9909 - precision: 0.9929 - recall: 0.9730\n","Epoch 00002: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.3896 - accuracy: 0.9909 - precision: 0.9929 - recall: 0.9730 - val_loss: 0.3396 - val_accuracy: 0.9921 - val_precision: 0.9932 - val_recall: 0.9834\n","Epoch 3/150\n","720/720 [==============================] - ETA: 0s - loss: 0.2914 - accuracy: 0.9930 - precision: 0.9935 - recall: 0.9883\n","Epoch 00003: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.2914 - accuracy: 0.9930 - precision: 0.9935 - recall: 0.9883 - val_loss: 0.2653 - val_accuracy: 0.9934 - val_precision: 0.9938 - val_recall: 0.9908\n","Epoch 4/150\n","720/720 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9937 - precision: 0.9940 - recall: 0.9918\n","Epoch 00004: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.2333 - accuracy: 0.9937 - precision: 0.9940 - recall: 0.9918 - val_loss: 0.2170 - val_accuracy: 0.9939 - val_precision: 0.9942 - val_recall: 0.9927\n","Epoch 5/150\n","720/720 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9941 - precision: 0.9943 - recall: 0.9932\n","Epoch 00005: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.1933 - accuracy: 0.9941 - precision: 0.9943 - recall: 0.9932 - val_loss: 0.1823 - val_accuracy: 0.9943 - val_precision: 0.9943 - val_recall: 0.9936\n","Epoch 6/150\n","720/720 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9943 - precision: 0.9943 - recall: 0.9939\n","Epoch 00006: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.1640 - accuracy: 0.9943 - precision: 0.9943 - recall: 0.9939 - val_loss: 0.1524 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9943\n","Epoch 7/150\n","720/720 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9943\n","Epoch 00007: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.1410 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9943 - val_loss: 0.1309 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9943\n","Epoch 8/150\n","720/720 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00008: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.1222 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.1119 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 9/150\n","720/720 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00009: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.1064 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0982 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 10/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00010: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0929 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0856 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 11/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00011: loss did not improve from 0.76792\n","720/720 [==============================] - 403s 560ms/step - loss: 0.0816 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0733 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 12/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00012: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0720 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0648 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 13/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00013: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0638 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0573 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9943\n","Epoch 14/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00014: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0567 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0510 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 15/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00015: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0507 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0450 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 16/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944\n","Epoch 00016: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0457 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0405 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9943\n","Epoch 17/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9943\n","Epoch 00017: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0416 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9943 - val_loss: 0.0366 - val_accuracy: 0.9944 - val_precision: 0.9946 - val_recall: 0.9942\n","Epoch 18/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9943\n","Epoch 00018: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0383 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9943 - val_loss: 0.0336 - val_accuracy: 0.9944 - val_precision: 0.9946 - val_recall: 0.9942\n","Epoch 19/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9944 - precision: 0.9945 - recall: 0.9943\n","Epoch 00019: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0355 - accuracy: 0.9944 - precision: 0.9945 - recall: 0.9943 - val_loss: 0.0354 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 20/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9944 - precision: 0.9945 - recall: 0.9943\n","Epoch 00020: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0332 - accuracy: 0.9944 - precision: 0.9945 - recall: 0.9943 - val_loss: 0.0290 - val_accuracy: 0.9944 - val_precision: 0.9949 - val_recall: 0.9940\n","Epoch 21/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9944 - precision: 0.9946 - recall: 0.9942\n","Epoch 00021: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0314 - accuracy: 0.9944 - precision: 0.9946 - recall: 0.9942 - val_loss: 0.0277 - val_accuracy: 0.9944 - val_precision: 0.9946 - val_recall: 0.9942\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9944 - precision: 0.9947 - recall: 0.9941\n","Epoch 00022: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0298 - accuracy: 0.9944 - precision: 0.9947 - recall: 0.9941 - val_loss: 0.0257 - val_accuracy: 0.9944 - val_precision: 0.9946 - val_recall: 0.9942\n","Epoch 23/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9944 - precision: 0.9947 - recall: 0.9941\n","Epoch 00023: loss did not improve from 0.76792\n","720/720 [==============================] - 403s 560ms/step - loss: 0.0285 - accuracy: 0.9944 - precision: 0.9947 - recall: 0.9941 - val_loss: 0.0244 - val_accuracy: 0.9944 - val_precision: 0.9950 - val_recall: 0.9938\n","Epoch 24/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9944 - precision: 0.9948 - recall: 0.9940\n","Epoch 00024: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0274 - accuracy: 0.9944 - precision: 0.9948 - recall: 0.9940 - val_loss: 0.0234 - val_accuracy: 0.9944 - val_precision: 0.9952 - val_recall: 0.9937\n","Epoch 25/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9944 - precision: 0.9948 - recall: 0.9940\n","Epoch 00025: loss did not improve from 0.76792\n","720/720 [==============================] - 403s 560ms/step - loss: 0.0265 - accuracy: 0.9944 - precision: 0.9948 - recall: 0.9940 - val_loss: 0.0227 - val_accuracy: 0.9944 - val_precision: 0.9950 - val_recall: 0.9939\n","Epoch 26/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9944 - precision: 0.9949 - recall: 0.9940\n","Epoch 00026: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0257 - accuracy: 0.9944 - precision: 0.9949 - recall: 0.9940 - val_loss: 0.0216 - val_accuracy: 0.9944 - val_precision: 0.9953 - val_recall: 0.9936\n","Epoch 27/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9944 - precision: 0.9949 - recall: 0.9939\n","Epoch 00027: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0250 - accuracy: 0.9944 - precision: 0.9949 - recall: 0.9939 - val_loss: 0.0227 - val_accuracy: 0.9944 - val_precision: 0.9950 - val_recall: 0.9939\n","Epoch 28/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939\n","Epoch 00028: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0244 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939 - val_loss: 0.0206 - val_accuracy: 0.9944 - val_precision: 0.9954 - val_recall: 0.9936\n","Epoch 29/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939\n","Epoch 00029: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0239 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939 - val_loss: 0.0203 - val_accuracy: 0.9944 - val_precision: 0.9953 - val_recall: 0.9937\n","Epoch 30/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939\n","Epoch 00030: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0234 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939 - val_loss: 0.0205 - val_accuracy: 0.9944 - val_precision: 0.9952 - val_recall: 0.9937\n","Epoch 31/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939\n","Epoch 00031: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0230 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939 - val_loss: 0.0194 - val_accuracy: 0.9944 - val_precision: 0.9952 - val_recall: 0.9938\n","Epoch 32/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939\n","Epoch 00032: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0226 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939 - val_loss: 0.0192 - val_accuracy: 0.9944 - val_precision: 0.9952 - val_recall: 0.9937\n","Epoch 33/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939\n","Epoch 00033: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0222 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939 - val_loss: 0.0263 - val_accuracy: 0.9944 - val_precision: 0.9945 - val_recall: 0.9943\n","Epoch 34/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939\n","Epoch 00034: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0219 - accuracy: 0.9944 - precision: 0.9950 - recall: 0.9939 - val_loss: 0.0186 - val_accuracy: 0.9944 - val_precision: 0.9952 - val_recall: 0.9938\n","Epoch 35/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9945 - precision: 0.9950 - recall: 0.9940\n","Epoch 00035: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0216 - accuracy: 0.9945 - precision: 0.9950 - recall: 0.9940 - val_loss: 0.0186 - val_accuracy: 0.9944 - val_precision: 0.9954 - val_recall: 0.9935\n","Epoch 36/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9945 - precision: 0.9950 - recall: 0.9940\n","Epoch 00036: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0213 - accuracy: 0.9945 - precision: 0.9950 - recall: 0.9940 - val_loss: 0.0184 - val_accuracy: 0.9944 - val_precision: 0.9953 - val_recall: 0.9937\n","Epoch 37/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9941\n","Epoch 00037: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0210 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9941 - val_loss: 0.0181 - val_accuracy: 0.9944 - val_precision: 0.9952 - val_recall: 0.9938\n","Epoch 38/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9941\n","Epoch 00038: loss did not improve from 0.76792\n","720/720 [==============================] - 410s 569ms/step - loss: 0.0208 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9941 - val_loss: 0.0179 - val_accuracy: 0.9944 - val_precision: 0.9952 - val_recall: 0.9938\n","Epoch 39/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9941\n","Epoch 00039: loss did not improve from 0.76792\n","720/720 [==============================] - 403s 559ms/step - loss: 0.0205 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9941 - val_loss: 0.0177 - val_accuracy: 0.9944 - val_precision: 0.9952 - val_recall: 0.9937\n","Epoch 40/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9942\n","Epoch 00040: loss did not improve from 0.76792\n","720/720 [==============================] - 408s 567ms/step - loss: 0.0203 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9942 - val_loss: 0.0177 - val_accuracy: 0.9945 - val_precision: 0.9951 - val_recall: 0.9939\n","Epoch 41/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9942\n","Epoch 00041: loss did not improve from 0.76792\n","720/720 [==============================] - 407s 565ms/step - loss: 0.0201 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9942 - val_loss: 0.0179 - val_accuracy: 0.9945 - val_precision: 0.9950 - val_recall: 0.9940\n","Epoch 42/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9942\n","Epoch 00042: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0199 - accuracy: 0.9945 - precision: 0.9949 - recall: 0.9942 - val_loss: 0.0196 - val_accuracy: 0.9944 - val_precision: 0.9948 - val_recall: 0.9942\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 43/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9945 - precision: 0.9948 - recall: 0.9943\n","Epoch 00043: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0197 - accuracy: 0.9945 - precision: 0.9948 - recall: 0.9943 - val_loss: 0.0176 - val_accuracy: 0.9945 - val_precision: 0.9949 - val_recall: 0.9941\n","Epoch 44/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9945 - precision: 0.9948 - recall: 0.9943\n","Epoch 00044: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0196 - accuracy: 0.9945 - precision: 0.9948 - recall: 0.9943 - val_loss: 0.0174 - val_accuracy: 0.9945 - val_precision: 0.9949 - val_recall: 0.9941\n","Epoch 45/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9943\n","Epoch 00045: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0194 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9943 - val_loss: 0.0169 - val_accuracy: 0.9945 - val_precision: 0.9950 - val_recall: 0.9941\n","Epoch 46/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9943\n","Epoch 00046: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0193 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9943 - val_loss: 0.0176 - val_accuracy: 0.9945 - val_precision: 0.9949 - val_recall: 0.9942\n","Epoch 47/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944\n","Epoch 00047: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0191 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944 - val_loss: 0.0175 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9942\n","Epoch 48/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944\n","Epoch 00048: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0190 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944 - val_loss: 0.0165 - val_accuracy: 0.9945 - val_precision: 0.9949 - val_recall: 0.9942\n","Epoch 49/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944\n","Epoch 00049: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0189 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944 - val_loss: 0.0184 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9943\n","Epoch 50/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944\n","Epoch 00050: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0187 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944 - val_loss: 0.0167 - val_accuracy: 0.9945 - val_precision: 0.9949 - val_recall: 0.9942\n","Epoch 51/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944\n","Epoch 00051: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0187 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944 - val_loss: 0.0161 - val_accuracy: 0.9945 - val_precision: 0.9949 - val_recall: 0.9942\n","Epoch 52/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944\n","Epoch 00052: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0185 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944 - val_loss: 0.0160 - val_accuracy: 0.9945 - val_precision: 0.9949 - val_recall: 0.9943\n","Epoch 53/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945\n","Epoch 00053: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0184 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945 - val_loss: 0.0164 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9943\n","Epoch 54/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945\n","Epoch 00054: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0183 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945 - val_loss: 0.0162 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9943\n","Epoch 55/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945\n","Epoch 00055: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0182 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945 - val_loss: 0.0163 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9943\n","Epoch 56/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945\n","Epoch 00056: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0181 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945 - val_loss: 0.0160 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9943\n","Epoch 57/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945\n","Epoch 00057: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0181 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9945 - val_loss: 0.0253 - val_accuracy: 0.9944 - val_precision: 0.9945 - val_recall: 0.9944\n","Epoch 58/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9945\n","Epoch 00058: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0179 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9945 - val_loss: 0.0161 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9943\n","Epoch 59/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9945\n","Epoch 00059: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0179 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9945 - val_loss: 0.0157 - val_accuracy: 0.9946 - val_precision: 0.9949 - val_recall: 0.9943\n","Epoch 60/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946\n","Epoch 00060: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0178 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946 - val_loss: 0.0164 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9944\n","Epoch 61/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946\n","Epoch 00061: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0177 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946 - val_loss: 0.0163 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9944\n","Epoch 62/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946\n","Epoch 00062: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0176 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946 - val_loss: 0.0159 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9944\n","Epoch 63/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946\n","Epoch 00063: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0175 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946 - val_loss: 0.0225 - val_accuracy: 0.9944 - val_precision: 0.9945 - val_recall: 0.9944\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 64/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946\n","Epoch 00064: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0174 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946 - val_loss: 0.0161 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9943\n","Epoch 65/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946\n","Epoch 00065: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0174 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946 - val_loss: 0.0154 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9944\n","Epoch 66/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946\n","Epoch 00066: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0173 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9946 - val_loss: 0.0160 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9944\n","Epoch 67/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9947\n","Epoch 00067: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0172 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9947 - val_loss: 0.0154 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9944\n","Epoch 68/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947\n","Epoch 00068: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0171 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947 - val_loss: 0.0158 - val_accuracy: 0.9945 - val_precision: 0.9948 - val_recall: 0.9943\n","Epoch 69/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947\n","Epoch 00069: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0171 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947 - val_loss: 0.0162 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9944\n","Epoch 70/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947\n","Epoch 00070: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0170 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947 - val_loss: 0.0154 - val_accuracy: 0.9946 - val_precision: 0.9949 - val_recall: 0.9944\n","Epoch 71/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947\n","Epoch 00071: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0170 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947 - val_loss: 0.0220 - val_accuracy: 0.9945 - val_precision: 0.9945 - val_recall: 0.9944\n","Epoch 72/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947\n","Epoch 00072: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0169 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947 - val_loss: 0.0152 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9945\n","Epoch 73/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947\n","Epoch 00073: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0168 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9947 - val_loss: 0.0158 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9945\n","Epoch 74/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9948\n","Epoch 00074: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0168 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9948 - val_loss: 0.0155 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9945\n","Epoch 75/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9948\n","Epoch 00075: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0167 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9948 - val_loss: 0.0244 - val_accuracy: 0.9945 - val_precision: 0.9945 - val_recall: 0.9944\n","Epoch 76/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9948\n","Epoch 00076: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0167 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9948 - val_loss: 0.0182 - val_accuracy: 0.9945 - val_precision: 0.9947 - val_recall: 0.9944\n","Epoch 77/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9949 - precision: 0.9949 - recall: 0.9948\n","Epoch 00077: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0166 - accuracy: 0.9949 - precision: 0.9949 - recall: 0.9948 - val_loss: 0.0298 - val_accuracy: 0.9944 - val_precision: 0.9944 - val_recall: 0.9944\n","Epoch 78/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9948\n","Epoch 00078: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0166 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9948 - val_loss: 0.0152 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9945\n","Epoch 79/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9948\n","Epoch 00079: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0164 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9948 - val_loss: 0.0156 - val_accuracy: 0.9947 - val_precision: 0.9948 - val_recall: 0.9945\n","Epoch 80/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9948\n","Epoch 00080: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0164 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9948 - val_loss: 0.0152 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9945\n","Epoch 81/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9948\n","Epoch 00081: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0164 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9948 - val_loss: 0.0150 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9945\n","Epoch 82/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9949\n","Epoch 00082: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0163 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9949 - val_loss: 0.0151 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9945\n","Epoch 83/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9949\n","Epoch 00083: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0163 - accuracy: 0.9949 - precision: 0.9950 - recall: 0.9949 - val_loss: 0.0153 - val_accuracy: 0.9946 - val_precision: 0.9948 - val_recall: 0.9945\n","Epoch 84/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9949\n","Epoch 00084: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0162 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9949 - val_loss: 0.0150 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9945\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 85/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9949\n","Epoch 00085: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0162 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9949 - val_loss: 0.0161 - val_accuracy: 0.9947 - val_precision: 0.9948 - val_recall: 0.9945\n","Epoch 86/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9949\n","Epoch 00086: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0161 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9949 - val_loss: 0.0151 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9945\n","Epoch 87/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9949\n","Epoch 00087: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0161 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9949 - val_loss: 0.0149 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 88/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9949\n","Epoch 00088: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0160 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9949 - val_loss: 0.0148 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 89/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9950\n","Epoch 00089: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0160 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9950 - val_loss: 0.0144 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 90/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9950\n","Epoch 00090: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0160 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9950 - val_loss: 0.0156 - val_accuracy: 0.9947 - val_precision: 0.9948 - val_recall: 0.9946\n","Epoch 91/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9950\n","Epoch 00091: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0159 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9950 - val_loss: 0.0148 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 92/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9951 - precision: 0.9951 - recall: 0.9950\n","Epoch 00092: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0158 - accuracy: 0.9951 - precision: 0.9951 - recall: 0.9950 - val_loss: 0.0186 - val_accuracy: 0.9946 - val_precision: 0.9947 - val_recall: 0.9945\n","Epoch 93/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9951 - precision: 0.9951 - recall: 0.9950\n","Epoch 00093: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0158 - accuracy: 0.9951 - precision: 0.9951 - recall: 0.9950 - val_loss: 0.0152 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 94/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9951 - precision: 0.9951 - recall: 0.9950\n","Epoch 00094: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0158 - accuracy: 0.9951 - precision: 0.9951 - recall: 0.9950 - val_loss: 0.0156 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 95/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9950\n","Epoch 00095: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0157 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9950 - val_loss: 0.0148 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 96/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9951\n","Epoch 00096: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0157 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0153 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 97/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9951\n","Epoch 00097: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0157 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0147 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 98/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9951\n","Epoch 00098: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0156 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0152 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 99/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9951\n","Epoch 00099: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0156 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0147 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 100/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951\n","Epoch 00100: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0155 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0146 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 101/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951\n","Epoch 00101: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0155 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0152 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 102/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951\n","Epoch 00102: loss did not improve from 0.76792\n","720/720 [==============================] - 411s 570ms/step - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0150 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 103/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951\n","Epoch 00103: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0170 - val_accuracy: 0.9947 - val_precision: 0.9948 - val_recall: 0.9946\n","Epoch 104/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951\n","Epoch 00104: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9952 - recall: 0.9951 - val_loss: 0.0151 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 105/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952\n","Epoch 00105: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0153 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 106/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952\n","Epoch 00106: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0176 - val_accuracy: 0.9947 - val_precision: 0.9948 - val_recall: 0.9946\n","Epoch 107/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952\n","Epoch 00107: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0152 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0146 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9947\n","Epoch 108/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952\n","Epoch 00108: loss did not improve from 0.76792\n","720/720 [==============================] - 406s 564ms/step - loss: 0.0152 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0148 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 109/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952\n","Epoch 00109: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0152 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0145 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 110/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952\n","Epoch 00110: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0152 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0166 - val_accuracy: 0.9947 - val_precision: 0.9948 - val_recall: 0.9946\n","Epoch 111/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952\n","Epoch 00111: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0151 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0151 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 112/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952\n","Epoch 00112: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0151 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0147 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 113/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952\n","Epoch 00113: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0150 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0146 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 114/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952\n","Epoch 00114: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0151 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.0147 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 115/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953\n","Epoch 00115: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0150 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0145 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 116/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953\n","Epoch 00116: loss did not improve from 0.76792\n","720/720 [==============================] - 406s 563ms/step - loss: 0.0149 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0155 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 117/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953\n","Epoch 00117: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0149 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0194 - val_accuracy: 0.9946 - val_precision: 0.9947 - val_recall: 0.9946\n","Epoch 118/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953\n","Epoch 00118: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0149 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0193 - val_accuracy: 0.9946 - val_precision: 0.9947 - val_recall: 0.9946\n","Epoch 119/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953\n","Epoch 00119: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0149 - accuracy: 0.9953 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0145 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 120/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953\n","Epoch 00120: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0148 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0144 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 121/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953\n","Epoch 00121: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0148 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0146 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 122/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953\n","Epoch 00122: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0148 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0170 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 123/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953\n","Epoch 00123: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0147 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0144 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 124/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953\n","Epoch 00124: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0148 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9953 - val_loss: 0.0154 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9947\n","Epoch 125/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9954\n","Epoch 00125: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0147 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.0145 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9946\n","Epoch 126/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954\n","Epoch 00126: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0147 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0146 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 127/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954\n","Epoch 00127: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0147 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0144 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 128/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954\n","Epoch 00128: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0146 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0189 - val_accuracy: 0.9947 - val_precision: 0.9948 - val_recall: 0.9946\n","Epoch 129/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954\n","Epoch 00129: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0146 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0147 - val_accuracy: 0.9948 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 130/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954\n","Epoch 00130: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0145 - accuracy: 0.9954 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0144 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 131/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954\n","Epoch 00131: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0145 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0171 - val_accuracy: 0.9947 - val_precision: 0.9949 - val_recall: 0.9946\n","Epoch 132/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954\n","Epoch 00132: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0145 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0148 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9948\n","Epoch 133/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954\n","Epoch 00133: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0145 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0161 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9947\n","Epoch 134/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954\n","Epoch 00134: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0145 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0156 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9947\n","Epoch 135/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954\n","Epoch 00135: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 560ms/step - loss: 0.0144 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.0147 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 136/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9955\n","Epoch 00136: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0144 - accuracy: 0.9955 - precision: 0.9955 - recall: 0.9955 - val_loss: 0.0144 - val_accuracy: 0.9949 - val_precision: 0.9951 - val_recall: 0.9948\n","Epoch 137/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955\n","Epoch 00137: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0144 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0167 - val_accuracy: 0.9948 - val_precision: 0.9949 - val_recall: 0.9947\n","Epoch 138/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955\n","Epoch 00138: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0144 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0145 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9948\n","Epoch 139/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955\n","Epoch 00139: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0143 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0145 - val_accuracy: 0.9949 - val_precision: 0.9951 - val_recall: 0.9948\n","Epoch 140/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955\n","Epoch 00140: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0143 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0195 - val_accuracy: 0.9947 - val_precision: 0.9948 - val_recall: 0.9946\n","Epoch 141/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955\n","Epoch 00141: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0143 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0144 - val_accuracy: 0.9949 - val_precision: 0.9951 - val_recall: 0.9948\n","Epoch 142/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955\n","Epoch 00142: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0142 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0147 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 143/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955\n","Epoch 00143: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0148 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9948\n","Epoch 144/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955\n","Epoch 00144: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0148 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9948\n","Epoch 145/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955\n","Epoch 00145: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 561ms/step - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0146 - val_accuracy: 0.9949 - val_precision: 0.9951 - val_recall: 0.9948\n","Epoch 146/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955\n","Epoch 00146: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0149 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9948\n","Epoch 147/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955\n","Epoch 00147: loss did not improve from 0.76792\n","720/720 [==============================] - 406s 563ms/step - loss: 0.0141 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0144 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9948\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 148/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955\n","Epoch 00148: loss did not improve from 0.76792\n","720/720 [==============================] - 405s 562ms/step - loss: 0.0142 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9955 - val_loss: 0.0147 - val_accuracy: 0.9949 - val_precision: 0.9950 - val_recall: 0.9947\n","Epoch 149/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9956\n","Epoch 00149: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0141 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.0144 - val_accuracy: 0.9949 - val_precision: 0.9951 - val_recall: 0.9948\n","Epoch 150/150\n","720/720 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9956 - precision: 0.9957 - recall: 0.9956\n","Epoch 00150: loss did not improve from 0.76792\n","720/720 [==============================] - 404s 561ms/step - loss: 0.0141 - accuracy: 0.9956 - precision: 0.9957 - recall: 0.9956 - val_loss: 0.0144 - val_accuracy: 0.9949 - val_precision: 0.9951 - val_recall: 0.9948\n"]}],"source":["results = model.fit_generator(train_generator , steps_per_epoch=train_steps , epochs=150,\n","                              validation_data=val_generator,validation_steps=val_steps,callbacks=[mc,es,tb,cv])"]},{"cell_type":"code","execution_count":null,"id":"9cebcf6f","metadata":{"scrolled":true,"id":"9cebcf6f","outputId":"1db78f04-7857-4ab1-fe2f-3c2d7b85fe61"},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['loss', 'accuracy', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall'])\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["print(results.history.keys())\n","from matplotlib import pyplot as plt\n","plt.figure()\n","plt.plot(results.history['accuracy'], 'orange', label='Training accuracy')\n","plt.plot(results.history['val_accuracy'], 'blue', label='Validation accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy rate')\n","plt.legend()\n","plt.show()\n","\n","plt.figure()\n","plt.plot(results.history['loss'], 'red', label='Training loss')\n","plt.plot(results.history['val_loss'], 'green', label='Validation loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss rate')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"623dc820","metadata":{"id":"623dc820"},"outputs":[],"source":["img_mask = choice(val_pair)\n","img= img_to_array(load_img(img_mask[0] , target_size= (img_size,img_size)))\n","gt_img = img_to_array(load_img(img_mask[1] , target_size= (img_size,img_size)))"]},{"cell_type":"code","execution_count":null,"id":"604f9b41","metadata":{"id":"604f9b41"},"outputs":[],"source":["def make_prediction(model,img_path,shape):\n","    img= img_to_array(load_img(img_path , target_size= shape))/255.\n","    img = np.expand_dims(img,axis=0)\n","    labels = model.predict(img)\n","    labels = np.argmax(labels[0],axis=2)\n","    return labels"]},{"cell_type":"code","execution_count":null,"id":"653f1f48","metadata":{"id":"653f1f48","outputId":"a0cd2240-f30d-4e07-8a90-4ec2a43bad8a"},"outputs":[{"data":{"text/plain":["(512, 512)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["pred_label = make_prediction(model, img_mask[0], (img_size,img_size,3))\n","pred_label.shape"]},{"cell_type":"code","execution_count":null,"id":"82933d85","metadata":{"id":"82933d85"},"outputs":[],"source":["def form_colormap(prediction,mapping):\n","    h,w = prediction.shape\n","    color_label = np.zeros((h,w,3),dtype=np.uint8)    \n","    color_label = mapping[prediction]\n","    color_label = color_label.astype(np.uint8)\n","    return color_label"]},{"cell_type":"code","execution_count":null,"id":"4c32af61","metadata":{"id":"4c32af61"},"outputs":[],"source":["pred_colored = form_colormap(pred_label,np.array(class_map))"]},{"cell_type":"code","execution_count":null,"id":"9960c827","metadata":{"id":"9960c827","outputId":"859dbd92-1c33-4438-cb72-4506c8421e4e"},"outputs":[{"data":{"text/plain":["Text(0.5, 1.0, 'predicted labels')"]},"execution_count":31,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 1080x1080 with 3 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.figure(figsize=(15,15))\n","plt.subplot(131);plt.title('Original Image')\n","plt.imshow(img/255.)\n","plt.subplot(132);plt.title('True labels')\n","plt.imshow(gt_img/255.)\n","plt.subplot(133)\n","plt.imshow(pred_colored/255.);plt.title('predicted labels')"]},{"cell_type":"code","execution_count":null,"id":"d61af7e0","metadata":{"id":"d61af7e0","outputId":"e40236c7-cfea-453c-896d-ebd4fc1a1b15"},"outputs":[{"name":"stdout","output_type":"stream","text":["img1.png\n","img10.png\n","img100.png\n","img1000.png\n","img1001.png\n","img1002.png\n","img1003.png\n","img1004.png\n","img1005.png\n","img1006.png\n","img1007.png\n","img1008.png\n","img1009.png\n","img101.png\n","img1010.png\n","img1011.png\n","img1012.png\n","img1013.png\n","img1014.png\n","img1015.png\n","img1016.png\n","img1017.png\n","img1018.png\n","img1019.png\n","img102.png\n","img1020.png\n","img1021.png\n","img1022.png\n","img1023.png\n","img1024.png\n","img1025.png\n","img1026.png\n","img1027.png\n","img1028.png\n","img1029.png\n","img103.png\n","img1030.png\n","img1031.png\n","img1032.png\n","img1033.png\n","img1034.png\n","img1035.png\n","img1036.png\n","img1037.png\n","img1038.png\n","img1039.png\n","img104.png\n","img1040.png\n","img1041.png\n","img1042.png\n","img1043.png\n","img1044.png\n","img1045.png\n","img1046.png\n","img1047.png\n","img1048.png\n","img1049.png\n","img105.png\n","img1050.png\n","img1051.png\n","img1052.png\n","img1053.png\n","img1054.png\n","img1055.png\n","img1056.png\n","img1057.png\n","img1058.png\n","img1059.png\n","img106.png\n","img1060.png\n","img1061.png\n","img1062.png\n","img1063.png\n","img1064.png\n","img1065.png\n","img1066.png\n","img1067.png\n","img1068.png\n","img1069.png\n","img107.png\n","img1070.png\n","img1071.png\n","img1072.png\n","img1073.png\n","img1074.png\n","img1075.png\n","img1076.png\n","img1077.png\n","img1078.png\n","img1079.png\n","img108.png\n","img1080.png\n","img1081.png\n","img1082.png\n","img1083.png\n","img1084.png\n","img1085.png\n","img1086.png\n","img1087.png\n","img1088.png\n","img1089.png\n","img109.png\n","img1090.png\n","img1091.png\n","img1092.png\n","img1093.png\n","img1094.png\n","img1095.png\n","img1096.png\n","img1097.png\n","img1098.png\n","img1099.png\n","img11.png\n","img110.png\n","img1100.png\n","img1101.png\n","img1102.png\n","img1103.png\n","img1104.png\n","img1105.png\n","img1106.png\n","img1107.png\n","img1108.png\n","img1109.png\n","img111.png\n","img1110.png\n","img1111.png\n","img1112.png\n","img1113.png\n","img1114.png\n","img1115.png\n","img1116.png\n","img1117.png\n","img1118.png\n","img1119.png\n","img112.png\n","img1120.png\n","img1121.png\n","img1122.png\n","img1123.png\n","img1124.png\n","img1125.png\n","img1126.png\n","img1127.png\n","img1128.png\n","img1129.png\n","img113.png\n","img1130.png\n","img1131.png\n","img1132.png\n","img1133.png\n","img1134.png\n","img1135.png\n","img1136.png\n","img1137.png\n","img1138.png\n","img1139.png\n","img114.png\n","img1140.png\n","img1141.png\n","img1142.png\n","img1143.png\n","img1144.png\n","img1145.png\n","img1146.png\n","img1147.png\n","img1148.png\n","img1149.png\n","img115.png\n","img1150.png\n","img1151.png\n","img1152.png\n","img1153.png\n","img1154.png\n","img1155.png\n","img1156.png\n","img1157.png\n","img1158.png\n","img1159.png\n","img116.png\n","img1160.png\n","img1161.png\n","img1162.png\n","img1163.png\n","img1164.png\n","img1165.png\n","img1166.png\n","img1167.png\n","img1168.png\n","img1169.png\n","img117.png\n","img1170.png\n","img1171.png\n","img1172.png\n","img1173.png\n","img1174.png\n","img1175.png\n","img1176.png\n","img1177.png\n","img1178.png\n","img1179.png\n","img118.png\n","img1180.png\n","img1181.png\n","img1182.png\n","img1183.png\n","img1184.png\n","img1185.png\n","img1186.png\n","img1187.png\n","img1188.png\n","img1189.png\n","img119.png\n","img1190.png\n","img1191.png\n","img1192.png\n","img1193.png\n","img1194.png\n","img1195.png\n","img1196.png\n","img1197.png\n","img1198.png\n","img1199.png\n","img12.png\n","img120.png\n","img1200.png\n","img1201.png\n","img1202.png\n","img1203.png\n","img1204.png\n","img1205.png\n","img1206.png\n","img1207.png\n","img1208.png\n","img1209.png\n","img121.png\n","img1210.png\n","img1211.png\n","img1212.png\n","img1213.png\n","img1214.png\n","img1215.png\n","img1216.png\n","img1217.png\n","img1218.png\n","img1219.png\n","img122.png\n","img1220.png\n","img1221.png\n","img1222.png\n","img1223.png\n","img1224.png\n","img1225.png\n","img1226.png\n","img1227.png\n","img1228.png\n","img1229.png\n","img123.png\n","img1230.png\n","img1231.png\n","img1232.png\n","img1233.png\n","img1234.png\n","img1235.png\n","img1236.png\n","img1237.png\n","img1238.png\n","img1239.png\n","img124.png\n","img1240.png\n","img1241.png\n","img1242.png\n","img1243.png\n","img1244.png\n","img1245.png\n","img1246.png\n","img1247.png\n","img1248.png\n","img1249.png\n","img125.png\n","img1250.png\n","img1251.png\n","img1252.png\n","img1253.png\n","img1254.png\n","img1255.png\n","img1256.png\n","img1257.png\n","img1258.png\n","img1259.png\n","img126.png\n","img1260.png\n","img1261.png\n","img1262.png\n","img1263.png\n","img1264.png\n","img1265.png\n","img1266.png\n","img1267.png\n","img1268.png\n","img1269.png\n","img127.png\n","img1270.png\n","img1271.png\n","img1272.png\n","img1273.png\n","img1274.png\n","img1275.png\n","img1276.png\n","img1277.png\n","img1278.png\n","img1279.png\n","img128.png\n","img1280.png\n","img1281.png\n","img1282.png\n","img1283.png\n","img1284.png\n","img1285.png\n","img1286.png\n","img1287.png\n","img1288.png\n","img1289.png\n","img129.png\n","img1290.png\n","img1291.png\n","img1292.png\n","img1293.png\n","img1294.png\n","img1295.png\n","img1296.png\n","img1297.png\n","img1298.png\n","img1299.png\n","img13.png\n","img130.png\n","img1300.png\n","img1301.png\n","img1302.png\n","img1303.png\n","img1304.png\n","img1305.png\n","img1306.png\n","img1307.png\n","img1308.png\n","img1309.png\n","img131.png\n","img1310.png\n","img1311.png\n","img1312.png\n","img1313.png\n","img1314.png\n","img1315.png\n","img1316.png\n","img1317.png\n","img1318.png\n","img1319.png\n","img132.png\n","img1320.png\n","img1321.png\n","img1322.png\n","img1323.png\n","img1324.png\n","img1325.png\n","img1326.png\n","img1327.png\n","img1328.png\n","img1329.png\n","img133.png\n","img1330.png\n","img1331.png\n","img1332.png\n","img1333.png\n","img1334.png\n","img1335.png\n","img1336.png\n","img1337.png\n","img1338.png\n","img1339.png\n","img134.png\n","img1340.png\n","img1341.png\n","img1342.png\n","img1343.png\n","img1344.png\n","img1345.png\n","img1346.png\n","img1347.png\n","img1348.png\n","img1349.png\n","img135.png\n","img1350.png\n","img1351.png\n","img1352.png\n","img1353.png\n","img1354.png\n","img1355.png\n","img1356.png\n","img1357.png\n","img1358.png\n","img1359.png\n","img136.png\n","img1360.png\n","img1361.png\n","img1362.png\n","img1363.png\n","img1364.png\n","img1365.png\n","img1366.png\n","img1367.png\n","img1368.png\n","img1369.png\n","img137.png\n","img1370.png\n","img1371.png\n","img1372.png\n","img1373.png\n","img1374.png\n","img1375.png\n","img1376.png\n","img1377.png\n","img1378.png\n","img1379.png\n","img138.png\n","img1380.png\n","img1381.png\n","img1382.png\n","img1383.png\n","img1384.png\n","img1385.png\n","img1386.png\n","img1387.png\n","img1388.png\n","img1389.png\n","img139.png\n","img1390.png\n","img1391.png\n","img1392.png\n","img1393.png\n","img1394.png\n","img1395.png\n","img1396.png\n","img1397.png\n","img1398.png\n","img1399.png\n","img14.png\n","img140.png\n","img1400.png\n","img1401.png\n","img1402.png\n","img1403.png\n","img1404.png\n","img1405.png\n","img1406.png\n","img1407.png\n","img1408.png\n","img1409.png\n","img141.png\n","img1410.png\n","img1411.png\n","img1412.png\n","img1413.png\n","img1414.png\n","img1415.png\n","img1416.png\n","img1417.png\n","img1418.png\n","img1419.png\n","img142.png\n","img1420.png\n","img1421.png\n","img1422.png\n","img1423.png\n","img1424.png\n","img1425.png\n","img1426.png\n","img1427.png\n","img1428.png\n","img1429.png\n","img143.png\n","img1430.png\n","img1431.png\n","img1432.png\n","img1433.png\n","img1434.png\n","img1435.png\n","img1436.png\n","img1437.png\n","img1438.png\n","img1439.png\n","img144.png\n","img1440.png\n","img145.png\n","img146.png\n","img147.png\n","img148.png\n","img149.png\n","img15.png\n","img150.png\n","img151.png\n","img152.png\n","img153.png\n","img154.png\n","img155.png\n","img156.png\n","img157.png\n","img158.png\n","img159.png\n","img16.png\n","img160.png\n","img161.png\n","img162.png\n","img163.png\n","img164.png\n","img165.png\n","img166.png\n","img167.png\n","img168.png\n","img169.png\n","img17.png\n","img170.png\n","img171.png\n","img172.png\n","img173.png\n","img174.png\n","img175.png\n","img176.png\n","img177.png\n","img178.png\n","img179.png\n","img18.png\n","img180.png\n","img181.png\n","img182.png\n","img183.png\n","img184.png\n","img185.png\n","img186.png\n","img187.png\n","img188.png\n","img189.png\n","img19.png\n","img190.png\n","img191.png\n","img192.png\n","img193.png\n","img194.png\n","img195.png\n","img196.png\n","img197.png\n","img198.png\n","img199.png\n","img2.png\n","img20.png\n","img200.png\n","img201.png\n","img202.png\n","img203.png\n","img204.png\n","img205.png\n","img206.png\n","img207.png\n","img208.png\n","img209.png\n","img21.png\n","img210.png\n","img211.png\n","img212.png\n","img213.png\n","img214.png\n","img215.png\n","img216.png\n","img217.png\n","img218.png\n","img219.png\n","img22.png\n","img220.png\n","img221.png\n","img222.png\n","img223.png\n","img224.png\n","img225.png\n","img226.png\n","img227.png\n","img228.png\n","img229.png\n","img23.png\n","img230.png\n","img231.png\n","img232.png\n","img233.png\n","img234.png\n","img235.png\n","img236.png\n","img237.png\n","img238.png\n","img239.png\n","img24.png\n","img240.png\n","img241.png\n","img242.png\n","img243.png\n","img244.png\n","img245.png\n","img246.png\n","img247.png\n","img248.png\n","img249.png\n","img25.png\n","img250.png\n","img251.png\n","img252.png\n","img253.png\n","img254.png\n","img255.png\n","img256.png\n","img257.png\n","img258.png\n","img259.png\n","img26.png\n","img260.png\n","img261.png\n","img262.png\n","img263.png\n","img264.png\n","img265.png\n","img266.png\n","img267.png\n","img268.png\n","img269.png\n","img27.png\n","img270.png\n","img271.png\n","img272.png\n","img273.png\n","img274.png\n","img275.png\n","img276.png\n","img277.png\n","img278.png\n","img279.png\n","img28.png\n","img280.png\n","img281.png\n","img282.png\n","img283.png\n","img284.png\n","img285.png\n","img286.png\n","img287.png\n","img288.png\n","img289.png\n","img29.png\n","img290.png\n","img291.png\n","img292.png\n","img293.png\n","img294.png\n","img295.png\n","img296.png\n","img297.png\n","img298.png\n","img299.png\n","img3.png\n","img30.png\n","img300.png\n","img301.png\n","img302.png\n","img303.png\n","img304.png\n","img305.png\n","img306.png\n","img307.png\n","img308.png\n","img309.png\n","img31.png\n","img310.png\n","img311.png\n","img312.png\n","img313.png\n","img314.png\n","img315.png\n","img316.png\n","img317.png\n","img318.png\n","img319.png\n","img32.png\n","img320.png\n","img321.png\n","img322.png\n","img323.png\n","img324.png\n","img325.png\n","img326.png\n","img327.png\n","img328.png\n","img329.png\n","img33.png\n","img330.png\n","img331.png\n","img332.png\n","img333.png\n","img334.png\n","img335.png\n","img336.png\n","img337.png\n","img338.png\n","img339.png\n","img34.png\n","img340.png\n","img341.png\n"]},{"name":"stdout","output_type":"stream","text":["img342.png\n","img343.png\n","img344.png\n","img345.png\n","img346.png\n","img347.png\n","img348.png\n","img349.png\n","img35.png\n","img350.png\n","img351.png\n","img352.png\n","img353.png\n","img354.png\n","img355.png\n","img356.png\n","img357.png\n","img358.png\n","img359.png\n","img36.png\n","img360.png\n","img361.png\n","img362.png\n","img363.png\n","img364.png\n","img365.png\n","img366.png\n","img367.png\n","img368.png\n","img369.png\n","img37.png\n","img370.png\n","img371.png\n","img372.png\n","img373.png\n","img374.png\n","img375.png\n","img376.png\n","img377.png\n","img378.png\n","img379.png\n","img38.png\n","img380.png\n","img381.png\n","img382.png\n","img383.png\n","img384.png\n","img385.png\n","img386.png\n","img387.png\n","img388.png\n","img389.png\n","img39.png\n","img390.png\n","img391.png\n","img392.png\n","img393.png\n","img394.png\n","img395.png\n","img396.png\n","img397.png\n","img398.png\n","img399.png\n","img4.png\n","img40.png\n","img400.png\n","img401.png\n","img402.png\n","img403.png\n","img404.png\n","img405.png\n","img406.png\n","img407.png\n","img408.png\n","img409.png\n","img41.png\n","img410.png\n","img411.png\n","img412.png\n","img413.png\n","img414.png\n","img415.png\n","img416.png\n","img417.png\n","img418.png\n","img419.png\n","img42.png\n","img420.png\n","img421.png\n","img422.png\n","img423.png\n","img424.png\n","img425.png\n","img426.png\n","img427.png\n","img428.png\n","img429.png\n","img43.png\n","img430.png\n","img431.png\n","img432.png\n","img433.png\n","img434.png\n","img435.png\n","img436.png\n","img437.png\n","img438.png\n","img439.png\n","img44.png\n","img440.png\n","img441.png\n","img442.png\n","img443.png\n","img444.png\n","img445.png\n","img446.png\n","img447.png\n","img448.png\n","img449.png\n","img45.png\n","img450.png\n","img451.png\n","img452.png\n","img453.png\n","img454.png\n","img455.png\n","img456.png\n","img457.png\n","img458.png\n","img459.png\n","img46.png\n","img460.png\n","img461.png\n","img462.png\n","img463.png\n","img464.png\n","img465.png\n","img466.png\n","img467.png\n","img468.png\n","img469.png\n","img47.png\n","img470.png\n","img471.png\n","img472.png\n","img473.png\n","img474.png\n","img475.png\n","img476.png\n","img477.png\n","img478.png\n","img479.png\n","img48.png\n","img480.png\n","img481.png\n","img482.png\n","img483.png\n","img484.png\n","img485.png\n","img486.png\n","img487.png\n","img488.png\n","img489.png\n","img49.png\n","img490.png\n","img491.png\n","img492.png\n","img493.png\n","img494.png\n","img495.png\n","img496.png\n","img497.png\n","img498.png\n","img499.png\n","img5.png\n","img50.png\n","img500.png\n","img501.png\n","img502.png\n","img503.png\n","img504.png\n","img505.png\n","img506.png\n","img507.png\n","img508.png\n","img509.png\n","img51.png\n","img510.png\n","img511.png\n","img512.png\n","img513.png\n","img514.png\n","img515.png\n","img516.png\n","img517.png\n","img518.png\n","img519.png\n","img52.png\n","img520.png\n","img521.png\n","img522.png\n","img523.png\n","img524.png\n","img525.png\n","img526.png\n","img527.png\n","img528.png\n","img529.png\n","img53.png\n","img530.png\n","img531.png\n","img532.png\n","img533.png\n","img534.png\n","img535.png\n","img536.png\n","img537.png\n","img538.png\n","img539.png\n","img54.png\n","img540.png\n","img541.png\n","img542.png\n","img543.png\n","img544.png\n","img545.png\n","img546.png\n","img547.png\n","img548.png\n","img549.png\n","img55.png\n","img550.png\n","img551.png\n","img552.png\n","img553.png\n","img554.png\n","img555.png\n","img556.png\n","img557.png\n","img558.png\n","img559.png\n","img56.png\n","img560.png\n","img561.png\n","img562.png\n","img563.png\n","img564.png\n","img565.png\n","img566.png\n","img567.png\n","img568.png\n","img569.png\n","img57.png\n","img570.png\n","img571.png\n","img572.png\n","img573.png\n","img574.png\n","img575.png\n","img576.png\n","img577.png\n","img578.png\n","img579.png\n","img58.png\n","img580.png\n","img581.png\n","img582.png\n","img583.png\n","img584.png\n","img585.png\n","img586.png\n","img587.png\n","img588.png\n","img589.png\n","img59.png\n","img590.png\n","img591.png\n","img592.png\n","img593.png\n","img594.png\n","img595.png\n","img596.png\n","img597.png\n","img598.png\n","img599.png\n","img6.png\n","img60.png\n","img600.png\n","img601.png\n","img602.png\n","img603.png\n","img604.png\n","img605.png\n","img606.png\n","img607.png\n","img608.png\n","img609.png\n","img61.png\n","img610.png\n","img611.png\n","img612.png\n","img613.png\n","img614.png\n","img615.png\n","img616.png\n","img617.png\n","img618.png\n","img619.png\n","img62.png\n","img620.png\n","img621.png\n","img622.png\n","img623.png\n","img624.png\n","img625.png\n","img626.png\n","img627.png\n","img628.png\n","img629.png\n","img63.png\n","img630.png\n","img631.png\n","img632.png\n","img633.png\n","img634.png\n","img635.png\n","img636.png\n","img637.png\n","img638.png\n","img639.png\n","img64.png\n","img640.png\n","img641.png\n","img642.png\n","img643.png\n","img644.png\n","img645.png\n","img646.png\n","img647.png\n","img648.png\n","img649.png\n","img65.png\n","img650.png\n","img651.png\n","img652.png\n","img653.png\n","img654.png\n","img655.png\n","img656.png\n","img657.png\n","img658.png\n","img659.png\n","img66.png\n","img660.png\n","img661.png\n","img662.png\n","img663.png\n","img664.png\n","img665.png\n","img666.png\n","img667.png\n","img668.png\n","img669.png\n","img67.png\n","img670.png\n","img671.png\n","img672.png\n","img673.png\n","img674.png\n","img675.png\n","img676.png\n","img677.png\n","img678.png\n","img679.png\n","img68.png\n","img680.png\n","img681.png\n","img682.png\n","img683.png\n","img684.png\n","img685.png\n","img686.png\n","img687.png\n","img688.png\n","img689.png\n","img69.png\n","img690.png\n","img691.png\n","img692.png\n","img693.png\n","img694.png\n","img695.png\n","img696.png\n","img697.png\n","img698.png\n","img699.png\n","img7.png\n","img70.png\n","img700.png\n","img701.png\n","img702.png\n","img703.png\n","img704.png\n","img705.png\n","img706.png\n","img707.png\n","img708.png\n","img709.png\n","img71.png\n","img710.png\n","img711.png\n","img712.png\n","img713.png\n","img714.png\n","img715.png\n","img716.png\n","img717.png\n","img718.png\n","img719.png\n","img72.png\n","img720.png\n","img721.png\n","img722.png\n","img723.png\n","img724.png\n","img725.png\n","img726.png\n","img727.png\n","img728.png\n","img729.png\n","img73.png\n","img730.png\n","img731.png\n","img732.png\n","img733.png\n","img734.png\n","img735.png\n","img736.png\n","img737.png\n","img738.png\n","img739.png\n","img74.png\n","img740.png\n","img741.png\n","img742.png\n","img743.png\n","img744.png\n","img745.png\n","img746.png\n","img747.png\n","img748.png\n","img749.png\n","img75.png\n","img750.png\n","img751.png\n","img752.png\n","img753.png\n","img754.png\n","img755.png\n","img756.png\n","img757.png\n","img758.png\n","img759.png\n","img76.png\n","img760.png\n","img761.png\n","img762.png\n","img763.png\n","img764.png\n","img765.png\n","img766.png\n","img767.png\n","img768.png\n","img769.png\n","img77.png\n","img770.png\n","img771.png\n","img772.png\n","img773.png\n","img774.png\n","img775.png\n","img776.png\n","img777.png\n","img778.png\n","img779.png\n","img78.png\n","img780.png\n","img781.png\n","img782.png\n","img783.png\n","img784.png\n","img785.png\n","img786.png\n","img787.png\n","img788.png\n","img789.png\n","img79.png\n","img790.png\n","img791.png\n","img792.png\n","img793.png\n","img794.png\n","img795.png\n","img796.png\n","img797.png\n","img798.png\n","img799.png\n","img8.png\n","img80.png\n","img800.png\n","img801.png\n","img802.png\n","img803.png\n","img804.png\n","img805.png\n","img806.png\n","img807.png\n","img808.png\n","img809.png\n","img81.png\n","img810.png\n","img811.png\n","img812.png\n","img813.png\n","img814.png\n","img815.png\n","img816.png\n","img817.png\n","img818.png\n","img819.png\n","img82.png\n","img820.png\n","img821.png\n","img822.png\n","img823.png\n","img824.png\n","img825.png\n","img826.png\n","img827.png\n","img828.png\n","img829.png\n","img83.png\n","img830.png\n","img831.png\n","img832.png\n","img833.png\n","img834.png\n","img835.png\n","img836.png\n","img837.png\n","img838.png\n","img839.png\n","img84.png\n","img840.png\n","img841.png\n","img842.png\n","img843.png\n","img844.png\n","img845.png\n","img846.png\n","img847.png\n","img848.png\n","img849.png\n","img85.png\n","img850.png\n","img851.png\n","img852.png\n","img853.png\n","img854.png\n","img855.png\n","img856.png\n","img857.png\n","img858.png\n","img859.png\n","img86.png\n","img860.png\n","img861.png\n","img862.png\n","img863.png\n","img864.png\n","img865.png\n","img866.png\n","img867.png\n","img868.png\n","img869.png\n","img87.png\n","img870.png\n","img871.png\n","img872.png\n","img873.png\n","img874.png\n","img875.png\n","img876.png\n","img877.png\n","img878.png\n","img879.png\n","img88.png\n","img880.png\n","img881.png\n","img882.png\n","img883.png\n","img884.png\n","img885.png\n","img886.png\n","img887.png\n","img888.png\n","img889.png\n","img89.png\n","img890.png\n","img891.png\n","img892.png\n","img893.png\n","img894.png\n","img895.png\n","img896.png\n","img897.png\n","img898.png\n","img899.png\n","img9.png\n","img90.png\n","img900.png\n","img901.png\n","img902.png\n","img903.png\n","img904.png\n","img905.png\n","img906.png\n","img907.png\n","img908.png\n","img909.png\n","img91.png\n","img910.png\n","img911.png\n","img912.png\n","img913.png\n","img914.png\n","img915.png\n","img916.png\n","img917.png\n","img918.png\n","img919.png\n","img92.png\n","img920.png\n","img921.png\n","img922.png\n","img923.png\n","img924.png\n","img925.png\n","img926.png\n","img927.png\n","img928.png\n","img929.png\n","img93.png\n","img930.png\n","img931.png\n","img932.png\n","img933.png\n","img934.png\n","img935.png\n","img936.png\n","img937.png\n","img938.png\n","img939.png\n","img94.png\n","img940.png\n","img941.png\n","img942.png\n","img943.png\n","img944.png\n","img945.png\n","img946.png\n","img947.png\n","img948.png\n","img949.png\n","img95.png\n","img950.png\n","img951.png\n","img952.png\n","img953.png\n","img954.png\n","img955.png\n","img956.png\n","img957.png\n","img958.png\n","img959.png\n","img96.png\n","img960.png\n","img961.png\n","img962.png\n","img963.png\n","img964.png\n","img965.png\n","img966.png\n","img967.png\n","img968.png\n","img969.png\n","img97.png\n","img970.png\n","img971.png\n","img972.png\n","img973.png\n","img974.png\n","img975.png\n","img976.png\n","img977.png\n","img978.png\n","img979.png\n","img98.png\n","img980.png\n","img981.png\n","img982.png\n","img983.png\n","img984.png\n","img985.png\n","img986.png\n","img987.png\n","img988.png\n","img989.png\n","img99.png\n","img990.png\n","img991.png\n","img992.png\n","img993.png\n","img994.png\n","img995.png\n","img996.png\n","img997.png\n","img998.png\n","img999.png\n"]}],"source":["from matplotlib import cm\n","import os\n","from PIL import Image\n","\n","PATH = \"C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/test/\"\n","Copy_to_path=\"C:/Users/maste/OneDrive/Bureau/segmentation a-v code/09-02-2022/Nouveau dossier/\"\n","\n","for filename in os.listdir(PATH):\n","    img_mask = Image.open(os.path.join(PATH, filename))\n","    print(filename)\n","    pred_label = make_prediction(model, os.path.join(PATH, filename), (img_size,img_size,3))\n","    pred_colored = form_colormap(pred_label,np.array(class_map))\n","    plt.imsave(os.path.join(Copy_to_path, filename), pred_colored)"]},{"cell_type":"code","execution_count":null,"id":"74f5f18b","metadata":{"id":"74f5f18b"},"outputs":[],"source":["recall = tf.keras.metrics.Recall()\n","precision = tf.keras.metrics.Precision()"]},{"cell_type":"code","execution_count":null,"id":"db2b4252","metadata":{"id":"db2b4252"},"outputs":[],"source":["model.save_weights(\"best_weights.h5\")"]},{"cell_type":"code","execution_count":null,"id":"37b735da","metadata":{"id":"37b735da"},"outputs":[],"source":["model.compile(optimizer='adam', loss='categorical_crossentropy' ,metrics=['accuracy',recall,precision])\n","model.load_weights(\"best_weights.h5\")"]},{"cell_type":"code","execution_count":null,"id":"f77ad376","metadata":{"id":"f77ad376","outputId":"45428542-959b-4890-b96c-ba66352ea4f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["90/90 [==============================] - 36s 389ms/step - loss: 0.0144 - accuracy: 0.9949 - recall_1: 0.9948 - precision_1: 0.9951\n"]}],"source":["val_hist = model.evaluate(val_generator, steps = len(val_generator), verbose = 1)"]},{"cell_type":"code","execution_count":null,"id":"47023ce0","metadata":{"id":"47023ce0"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}